{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON data from the text file\n",
    "with open('feature-synonyms_Spanish.txt', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a DataFrame from the JSON data\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combining reviews\n",
    "\n",
    "# with open('../googleplay-apps.txt') as appfile:\n",
    "#     line = appfile.readline()\n",
    "\n",
    "#     while(line):\n",
    "#         app = line.strip()\n",
    "\n",
    "#         applestoredf = pd.read_csv('../review-files-Spanish-sentiment/applestore-review-' + app + '_Spanish_sentiment.csv')\n",
    "#         googleplaydf = pd.read_csv('../review-files-Spanish-sentiment/googleplay-review-' + app + '_Spanish_sentiment.csv')\n",
    "#         googleplaydf = googleplaydf.rename(columns={\"content\": \"review\", \"score\": \"rating\", \"at\": \"date\"})\n",
    "#         cdf = pd.concat([applestoredf, googleplaydf], ignore_index=True)\n",
    "\n",
    "#         cdf.to_csv('review-files-combined_Spanish/combined-review-' + app + 'Spanish_sentiment.csv', index=False)\n",
    "#         line = appfile.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codeacademy_Spanish_sentiment.csv\n",
      "programming-hero_Spanish_sentiment.csv\n",
      "mimo_Spanish_sentiment.csv\n",
      "sololearn_Spanish_sentiment.csv\n",
      "learn-python-programiz_Spanish_sentiment.csv\n",
      "datacamp_Spanish_sentiment.csv\n",
      "programming-hub_Spanish_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Standardize reviews\n",
    "\n",
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def standardize(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove diacritics and accents\n",
    "    text = unidecode(text)\n",
    "\n",
    "    # Tokenization\n",
    "    text = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "\n",
    "    # Return the standardized string\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined_Spanish/')]\n",
    "\n",
    "\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv('review-files-combined_Spanish/' + file)\n",
    "    df['content'] = df['content'].astype('str')\n",
    "\n",
    "    df['standardizedReview'] = df['content'].apply(standardize)\n",
    "\n",
    "    output_file = os.path.splitext(file)[0] + '_standardized.csv'\n",
    "\n",
    "    df.to_csv('review-files-combined-standardized_Spanish/' + output_file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Feature                   Synonym  Stem   SynonymStem\n",
      "0   días consecutivos         días consecutivos   NaN           dia\n",
      "1   días consecutivos           cadenas diarias   NaN        cadena\n",
      "2   días consecutivos             días seguidos   NaN           dia\n",
      "3   días consecutivos        secuencias diarias   NaN     secuencia\n",
      "4   días consecutivos  bonificaciones por racha   NaN  bonificacion\n",
      "..                ...                       ...   ...           ...\n",
      "85         coronación                coronación   NaN         coron\n",
      "86         coronación               investidura   NaN    investidur\n",
      "87         coronación        ceremonia de coron   NaN      ceremoni\n",
      "88         coronación                 elevación   NaN       elevaci\n",
      "89         coronación              coronamiento   NaN         coron\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "defaultdict(<class 'set'>, {'días consecutivos': {'cadena', 'secuencia', 'bonificacion', 'dia'}, 'sistema de puntos': {'mecanismo', 'sistema', 'asignacion', 'estructura'}, 'barra de progreso': {'visualizacion', 'indicador', 'barra', 'medidor'}, 'competencia de hábitos/golpe': {'racha', 'desafio', 'competencia', 'rutina', 'batalla'}, 'descubrimiento social': {'encuentro', 'conexion', 'descubrimiento', 'exploracion'}, 'desafíos': {'objetivo', 'desafio', 'tarea', 'prueba', 'mision'}, 'tablero de clasificación/competencia': {'marcador', 'tabla', 'lista', 'tablero', 'posicion'}, 'potenciadores': {'mejora', 'potenciador', 'objeto', 'refuerzo', 'amplificador'}, 'economía virtual': {'mercado', 'economia', 'sistema'}, 'descansos de tortura': {'intervalo', 'periodo', 'pausa', 'descanso'}, 'tumba visual': {'tumba', 'area', 'mostrador', 'sitio', 'memorial'}, 'choca esos cinco': {'intercambi', 'golpe', 'choque', 'gesto', 'chocar'}, 'última milla': {'última', 'esfuerz', 'impuls', 'empuj', 'motiv'}, 'desfile de anticipación': {'desfil', 'procesión', 'march', 'celebración', 'presentación'}, 'avatar': {'person', 'representación', 'personaj', 'avatar', 'identid'}, 'estados de victoria': {'estad', 'resultad', 'escenari', 'condicion'}, 'votación': {'tom', 'emisió', 'votaci', 'escrutini', 'elecc'}, 'coronación': {'ceremoni', 'coron', 'elevaci', 'investidur'}})\n"
     ]
    }
   ],
   "source": [
    "# Getting stems\n",
    "\n",
    "# from stemming.porter2 import stem\n",
    "from collections import defaultdict\n",
    "\n",
    "# with open('features.txt') as file:\n",
    "#     str = file.read()\n",
    "\n",
    "# features = [feature.strip() for feature in str.split(',')]\n",
    "\n",
    "df = pd.read_csv('feature-list_Spanish.csv')\n",
    "print(df)\n",
    "\n",
    "# def stem_phrase(phrase):\n",
    "#     words = phrase.split()\n",
    "#     stemmed_words = [stem(word) for word in words]\n",
    "#     return ' '.join(stemmed_words)\n",
    "\n",
    "# df['Stem'] = df['Feature'].apply(stem)\n",
    "\n",
    "# df['SynonymStem'] = df['Synonym'].apply(stem)\n",
    "# df['SynonymStem'] = df['SynonymStem'].apply(standardize)\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# df.to_csv('feature-list.csv', index=False)\n",
    "\n",
    "my_dict = defaultdict(set)\n",
    "for feature, synonym in zip(df['Feature'], df['SynonymStem']):\n",
    "    my_dict[feature].add(synonym)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn-python-programiz_Spanish_sentiment_standardized.csv\n",
      "mimo_Spanish_sentiment_standardized.csv\n",
      "codeacademy_Spanish_sentiment_standardized.csv\n",
      "programming-hub_Spanish_sentiment_standardized.csv\n",
      "datacamp_Spanish_sentiment_standardized.csv\n",
      "programming-hero_Spanish_sentiment_standardized.csv\n",
      "sololearn_Spanish_sentiment_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "# Filtering reviews\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined-standardized_Spanish/')]\n",
    "\n",
    "\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv('review-files-combined-standardized_Spanish/' + file)\n",
    "    df['standardizedReview'] = df['standardizedReview'].astype('str')\n",
    "    \n",
    "\n",
    "    df['mentionedFeature'] = df['standardizedReview'].apply(lambda x: ', '.join([feature for feature, synonyms in my_dict.items() if any(syn in x for syn in synonyms)]))\n",
    "    df['mentionedSynonyms'] = df['standardizedReview'].apply(lambda x: ', '.join([syn for feature, synonyms in my_dict.items() for syn in synonyms if syn in x]))\n",
    "\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['mentionedFeature'], inplace=True)\n",
    "    #df['standardizedReview'] = df['review'].apply(standardize)\n",
    "\n",
    "    output_file = os.path.splitext(file)[0] + '_filtered.csv'\n",
    "\n",
    "    df.to_csv('review-files-combined-filtered_Spanish/' + output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'días consecutivos': [0, 0], 'sistema de puntos': [0, 0], 'barra de progreso': [0, 0], 'competencia de hábitos/golpe': [0, 0], 'descubrimiento social': [0, 0], 'desafíos': [0, 0], 'tablero de clasificación/competencia': [0, 0], 'potenciadores': [0, 0], 'economía virtual': [0, 0], 'descansos de tortura': [0, 0], 'tumba visual': [0, 0], 'choca esos cinco': [0, 0], 'última milla': [0, 0], 'desfile de anticipación': [0, 0], 'avatar': [0, 0], 'estados de victoria': [0, 0], 'votación': [0, 0], 'coronación': [0, 0]})\n",
      "learn-python-programiz_Spanish_sentiment_standardized_filtered.csv\n",
      "programming-hero_Spanish_sentiment_standardized_filtered.csv\n",
      "sololearn_Spanish_sentiment_standardized_filtered.csv\n",
      "codeacademy_Spanish_sentiment_standardized_filtered.csv\n",
      "mimo_Spanish_sentiment_standardized_filtered.csv\n",
      "programming-hub_Spanish_sentiment_standardized_filtered.csv\n",
      "datacamp_Spanish_sentiment_standardized_filtered.csv\n",
      "defaultdict(<class 'list'>, {'días consecutivos': [870, -144, 0.7159763313609467], 'sistema de puntos': [255, -42, 0.7171717171717171], 'barra de progreso': [4, -9, -0.38461538461538464], 'competencia de hábitos/golpe': [200, -63, 0.5209125475285171], 'descubrimiento social': [74, -79, -0.032679738562091505], 'desafíos': [334, -111, 0.501123595505618], 'tablero de clasificación/competencia': [39, -9, 0.625], 'potenciadores': [409, -25, 0.8847926267281107], 'economía virtual': [138, -33, 0.6140350877192983], 'descansos de tortura': [11, -4, 0.4666666666666667], 'tumba visual': [96, -9, 0.8285714285714286], 'choca esos cinco': [9, 0, 1.0], 'última milla': [178, -10, 0.8936170212765957], 'desfile de anticipación': [7, 0, 1.0], 'avatar': [436, -53, 0.7832310838445807], 'estados de victoria': [89, -21, 0.6181818181818182], 'votación': [174, -44, 0.5963302752293578], 'coronación': [0, 0, 0]})\n"
     ]
    }
   ],
   "source": [
    "# Aggregating feature sentiments\n",
    "\n",
    "scores = defaultdict(list)\n",
    "for feature in my_dict.keys():\n",
    "    feature = feature.lower()\n",
    "    scores[feature] = [0, 0]\n",
    "\n",
    "print(scores)\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined-filtered_Spanish/')]\n",
    "\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv('review-files-combined-filtered_Spanish/' + file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        mentioned_features = [feature.strip() for feature in row['mentionedFeature'].split(',')]\n",
    "        #print(mentioned_features)\n",
    "        for feature in mentioned_features:\n",
    "            #print(feature)\n",
    "            if row['sentiment'] == 'POS':\n",
    "                scores[feature][0] += 1\n",
    "            elif row['sentiment'] == 'NEG':\n",
    "                scores[feature][1] -= 1\n",
    "            # elif row['sentiment'] == 'NEU':\n",
    "            #     scores[feature][2] += 1\n",
    "\n",
    "for feature in scores.keys():\n",
    "    if scores[feature][0] - scores[feature][1] == 0:\n",
    "        scores[feature].append(0)\n",
    "        continue\n",
    "    scores[feature].append((scores[feature][0] + scores[feature][1]) / (scores[feature][0] - scores[feature][1]))\n",
    "\n",
    "print(scores)\n",
    "\n",
    "overallscoredf = pd.DataFrame(columns = ['feature', 'positiveCount', 'negativeCount', 'score'])\n",
    "\n",
    "for feature in scores.keys():\n",
    "    new_row = pd.Series({'feature': feature, 'positiveCount': scores[feature][0], 'negativeCount': scores[feature][1], 'score': scores[feature][2]})\n",
    "    overallscoredf = pd.concat([overallscoredf, new_row.to_frame().T], ignore_index=False)\n",
    "\n",
    "overallscoredf.to_csv('feature-scores_Spanish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature sentiment per app\n",
    "\n",
    "scoredf = pd.DataFrame(columns = ['app', 'feature', 'positiveCount', 'negativeCount', 'score'])\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined-filtered_Spanish/')]\n",
    "\n",
    "with open('../googleplay-apps.txt') as appfile:\n",
    "    line = appfile.readline()\n",
    "\n",
    "    while(line):\n",
    "        app = line.strip()\n",
    "\n",
    "        if app == 'encode':\n",
    "            line = appfile.readline()\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv('review-files-combined-filtered_Spanish/' + app + '_Spanish_sentiment_standardized_filtered.csv')\n",
    "\n",
    "        appscores = defaultdict(list)\n",
    "        for feature in my_dict.keys():\n",
    "            feature = feature.lower()\n",
    "            appscores[feature] = [0, 0]\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            mentioned_features = [feature.strip() for feature in row['mentionedFeature'].split(',')]\n",
    "            #print(mentioned_features)\n",
    "            for feature in mentioned_features:\n",
    "                #print(feature)\n",
    "                if row['sentiment'] == 'POS':\n",
    "                    appscores[feature][0] += 1\n",
    "                elif row['sentiment'] == 'NEG':\n",
    "                    appscores[feature][1] -= 1\n",
    "\n",
    "        for feature in appscores.keys():\n",
    "            if appscores[feature][0] - appscores[feature][1] == 0:\n",
    "                appscores[feature].append(0)\n",
    "                continue\n",
    "            appscores[feature].append((appscores[feature][0] + appscores[feature][1]) / (appscores[feature][0] - appscores[feature][1]))\n",
    "\n",
    "        for feature in appscores.keys():\n",
    "            new_row = pd.Series({'app': app, 'feature': feature, 'positiveCount': appscores[feature][0], 'negativeCount': appscores[feature][1], 'score': appscores[feature][2]})\n",
    "            \n",
    "            scoredf = pd.concat([scoredf, new_row.to_frame().T], ignore_index=False)\n",
    "\n",
    "        line = appfile.readline()\n",
    "\n",
    "scoredf.to_csv('feature-scores-by-app-Spanish.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codeacademy\n",
      "datacamp\n",
      "learn-python-programiz\n",
      "mimo\n",
      "programming-hero\n",
      "programming-hub\n",
      "sololearn\n"
     ]
    }
   ],
   "source": [
    "# Overall sentiment per app\n",
    "sentimentdf = pd.DataFrame(columns = ['app', 'positiveCount', 'negativeCount', 'score'])\n",
    "\n",
    "with open('../googleplay-apps.txt') as appfile:\n",
    "    line = appfile.readline()\n",
    "\n",
    "    while(line):\n",
    "        app = line.strip()\n",
    "\n",
    "        if app == 'encode':\n",
    "            line = appfile.readline()\n",
    "            continue\n",
    "        \n",
    "        print(app)\n",
    "\n",
    "        df = pd.read_csv('review-files-combined_Spanish/' + app + '_Spanish_sentiment.csv')\n",
    "\n",
    "        positiveCount = 0\n",
    "        negativeCount = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            if row['sentiment'] == 'POS':\n",
    "                positiveCount += 1\n",
    "            elif row['sentiment'] == 'NEG':\n",
    "                negativeCount -= 1\n",
    "        \n",
    "        if positiveCount == 0 and negativeCount == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = (positiveCount + negativeCount) / (positiveCount - negativeCount)\n",
    "            \n",
    "        new_row = pd.Series({'app': app, 'positiveCount': positiveCount, 'negativeCount': negativeCount, 'score': score})\n",
    "        sentimentdf = pd.concat([sentimentdf, new_row.to_frame().T], ignore_index=False)\n",
    "\n",
    "        line = appfile.readline()\n",
    "\n",
    "sentimentdf.to_csv('app-scores_Spanish.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

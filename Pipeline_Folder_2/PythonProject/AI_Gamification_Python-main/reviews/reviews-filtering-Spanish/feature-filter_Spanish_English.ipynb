{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON data from the text file\n",
    "with open('feature-synonyms_Spanish.txt', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a DataFrame from the JSON data\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combining reviews\n",
    "\n",
    "# with open('../googleplay-apps.txt') as appfile:\n",
    "#     line = appfile.readline()\n",
    "\n",
    "#     while(line):\n",
    "#         app = line.strip()\n",
    "\n",
    "#         applestoredf = pd.read_csv('../review-files-Spanish-sentiment/applestore-review-' + app + '_Spanish_sentiment.csv')\n",
    "#         googleplaydf = pd.read_csv('../review-files-Spanish-sentiment/googleplay-review-' + app + '_Spanish_sentiment.csv')\n",
    "#         googleplaydf = googleplaydf.rename(columns={\"content\": \"review\", \"score\": \"rating\", \"at\": \"date\"})\n",
    "#         cdf = pd.concat([applestoredf, googleplaydf], ignore_index=True)\n",
    "\n",
    "#         cdf.to_csv('review-files-combined_Spanish/combined-review-' + app + 'Spanish_sentiment.csv', index=False)\n",
    "#         line = appfile.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codeacademy_Spanish_sentiment.csv\n",
      "programming-hero_Spanish_sentiment.csv\n",
      "mimo_Spanish_sentiment.csv\n",
      "sololearn_Spanish_sentiment.csv\n",
      "learn-python-programiz_Spanish_sentiment.csv\n",
      "datacamp_Spanish_sentiment.csv\n",
      "programming-hub_Spanish_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Standardize reviews\n",
    "\n",
    "import string\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def standardize(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove diacritics and accents\n",
    "    text = unidecode(text)\n",
    "\n",
    "    # Tokenization\n",
    "    text = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "\n",
    "    # Return the standardized string\n",
    "    return ' '.join(text)\n",
    "\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined_Spanish/')]\n",
    "\n",
    "\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv('review-files-combined_Spanish/' + file)\n",
    "    df['content'] = df['content'].astype('str')\n",
    "\n",
    "    df['standardizedReview'] = df['content'].apply(standardize)\n",
    "\n",
    "    output_file = os.path.splitext(file)[0] + '_standardized.csv'\n",
    "\n",
    "    df.to_csv('review-files-combined-standardized_Spanish/' + output_file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature                   Synonym  Stem   SynonymStem\n",
      "0   daily streaks         días consecutivos   NaN           dia\n",
      "1   daily streaks           cadenas diarias   NaN        cadena\n",
      "2   daily streaks             días seguidos   NaN           dia\n",
      "3   daily streaks        secuencias diarias   NaN     secuencia\n",
      "4   daily streaks  bonificaciones por racha   NaN  bonificacion\n",
      "..            ...                       ...   ...           ...\n",
      "85       crowning                coronación   NaN         coron\n",
      "86       crowning               investidura   NaN    investidur\n",
      "87       crowning        ceremonia de coron   NaN      ceremoni\n",
      "88       crowning                 elevación   NaN       elevaci\n",
      "89       crowning              coronamiento   NaN         coron\n",
      "\n",
      "[90 rows x 4 columns]\n",
      "defaultdict(<class 'set'>, {'daily streaks': {'dia', 'cadena', 'secuencia', 'bonificacion'}, 'points system': {'asignacion', 'sistema', 'mecanismo', 'estructura'}, 'progress bar': {'indicador', 'medidor', 'visualizacion', 'barra'}, 'strike habit/competition': {'desafio', 'competencia', 'batalla', 'racha', 'rutina'}, 'social discovery': {'descubrimiento', 'encuentro', 'conexion', 'exploracion'}, 'challenges': {'prueba', 'desafio', 'tarea', 'mision', 'objetivo'}, 'leaderboard/competition': {'posicion', 'tablero', 'marcador', 'tabla', 'lista'}, 'boosters': {'amplificador', 'mejora', 'refuerzo', 'objeto', 'potenciador'}, 'virtual economy': {'sistema', 'economia', 'mercado'}, 'torture breaks': {'intervalo', 'descanso', 'pausa', 'periodo'}, 'visual grave': {'area', 'sitio', 'tumba', 'mostrador', 'memorial'}, 'high five': {'choque', 'golpe', 'intercambi', 'chocar', 'gesto'}, 'last mile drive': {'última', 'motiv', 'esfuerz', 'impuls', 'empuj'}, 'anticipation parade': {'desfil', 'celebración', 'procesión', 'march', 'presentación'}, 'avatar': {'person', 'personaj', 'avatar', 'representación', 'identid'}, 'win states': {'condicion', 'resultad', 'escenari', 'estad'}, 'voting': {'votaci', 'tom', 'emisió', 'elecc', 'escrutini'}, 'crowning': {'investidur', 'coron', 'elevaci', 'ceremoni'}})\n"
     ]
    }
   ],
   "source": [
    "# Getting stems\n",
    "\n",
    "# from stemming.porter2 import stem\n",
    "from collections import defaultdict\n",
    "\n",
    "# with open('features.txt') as file:\n",
    "#     str = file.read()\n",
    "\n",
    "# features = [feature.strip() for feature in str.split(',')]\n",
    "\n",
    "df = pd.read_csv('feature-list_Spanish.csv')\n",
    "print(df)\n",
    "\n",
    "# def stem_phrase(phrase):\n",
    "#     words = phrase.split()\n",
    "#     stemmed_words = [stem(word) for word in words]\n",
    "#     return ' '.join(stemmed_words)\n",
    "\n",
    "# df['Stem'] = df['Feature'].apply(stem)\n",
    "\n",
    "# df['SynonymStem'] = df['Synonym'].apply(stem)\n",
    "# df['SynonymStem'] = df['SynonymStem'].apply(standardize)\n",
    "\n",
    "# print(df)\n",
    "\n",
    "# df.to_csv('feature-list.csv', index=False)\n",
    "\n",
    "my_dict = defaultdict(set)\n",
    "for feature, synonym in zip(df['Feature'], df['SynonymStem']):\n",
    "    my_dict[feature].add(synonym)\n",
    "\n",
    "# Print the resulting dictionary\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn-python-programiz_Spanish_sentiment_standardized.csv\n",
      "mimo_Spanish_sentiment_standardized.csv\n",
      "codeacademy_Spanish_sentiment_standardized.csv\n",
      "programming-hub_Spanish_sentiment_standardized.csv\n",
      "datacamp_Spanish_sentiment_standardized.csv\n",
      "programming-hero_Spanish_sentiment_standardized.csv\n",
      "sololearn_Spanish_sentiment_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "# Filtering reviews\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined-standardized_Spanish/')]\n",
    "\n",
    "\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv('review-files-combined-standardized_Spanish/' + file)\n",
    "    df['standardizedReview'] = df['standardizedReview'].astype('str')\n",
    "    \n",
    "    # df = df[df['standardizedReview'].str.contains('python', case=False)]\n",
    "    # df = df.dropna(subset=['standardizedReview'])\n",
    "\n",
    "    df['mentionedFeature'] = df['standardizedReview'].apply(lambda x: ', '.join([feature for feature, synonyms in my_dict.items() if any(syn in x for syn in synonyms)]))\n",
    "    df['mentionedSynonyms'] = df['standardizedReview'].apply(lambda x: ', '.join([syn for feature, synonyms in my_dict.items() for syn in synonyms if syn in x]))\n",
    "\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['mentionedFeature'], inplace=True)\n",
    "    #df['standardizedReview'] = df['review'].apply(standardize)\n",
    "\n",
    "    output_file = os.path.splitext(file)[0] + '_filtered.csv'\n",
    "\n",
    "    df.to_csv('review-files-combined-filtered_Spanish/' + output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'daily streaks': [0, 0], 'points system': [0, 0], 'progress bar': [0, 0], 'strike habit/competition': [0, 0], 'social discovery': [0, 0], 'challenges': [0, 0], 'leaderboard/competition': [0, 0], 'boosters': [0, 0], 'virtual economy': [0, 0], 'torture breaks': [0, 0], 'visual grave': [0, 0], 'high five': [0, 0], 'last mile drive': [0, 0], 'anticipation parade': [0, 0], 'avatar': [0, 0], 'win states': [0, 0], 'voting': [0, 0], 'crowning': [0, 0], 'status quo sloth': [0, 0]})\n",
      "learn-python-programiz_Spanish_sentiment_standardized_filtered.csv\n",
      "programming-hero_Spanish_sentiment_standardized_filtered.csv\n",
      "sololearn_Spanish_sentiment_standardized_filtered.csv\n",
      "codeacademy_Spanish_sentiment_standardized_filtered.csv\n",
      "mimo_Spanish_sentiment_standardized_filtered.csv\n",
      "programming-hub_Spanish_sentiment_standardized_filtered.csv\n",
      "datacamp_Spanish_sentiment_standardized_filtered.csv\n",
      "defaultdict(<class 'list'>, {'daily streaks': [20, -3, 0.7391304347826086], 'points system': [3, -3, 0.0], 'progress bar': [0, 0, 0], 'strike habit/competition': [3, 0, 1.0], 'social discovery': [1, -1, 0.0], 'challenges': [7, -1, 0.75], 'leaderboard/competition': [0, 0, 0], 'boosters': [7, -1, 0.75], 'virtual economy': [1, -1, 0.0], 'torture breaks': [0, 0, 0], 'visual grave': [2, 0, 1.0], 'high five': [0, 0, 0], 'last mile drive': [4, 0, 1.0], 'anticipation parade': [0, 0, 0], 'avatar': [8, 0, 1.0], 'win states': [1, 0, 1.0], 'voting': [4, 0, 1.0], 'crowning': [0, 0, 0], 'status quo sloth': [8, 0, 1.0]})\n"
     ]
    }
   ],
   "source": [
    "# Aggregating feature sentiments\n",
    "\n",
    "scores = defaultdict(list)\n",
    "for feature in my_dict.keys():\n",
    "    feature = feature.lower()\n",
    "    scores[feature] = [0, 0]\n",
    "\n",
    "print(scores)\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined-filtered-python_Spanish_English/')]\n",
    "\n",
    "for file in filelist:\n",
    "    print(file)\n",
    "\n",
    "    df = pd.read_csv('review-files-combined-filtered-python_Spanish_English/' + file)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        mentioned_features = [feature.strip() for feature in row['mentionedFeature'].split(',')]\n",
    "        #print(mentioned_features)\n",
    "        for feature in mentioned_features:\n",
    "            #print(feature)\n",
    "            if row['sentiment'] == 'POS':\n",
    "                scores[feature][0] += 1\n",
    "            elif row['sentiment'] == 'NEG':\n",
    "                scores[feature][1] -= 1\n",
    "            # elif row['sentiment'] == 'NEU':\n",
    "            #     scores[feature][2] += 1\n",
    "\n",
    "for feature in scores.keys():\n",
    "    if scores[feature][0] - scores[feature][1] == 0:\n",
    "        scores[feature].append(0)\n",
    "        continue\n",
    "    scores[feature].append((scores[feature][0] + scores[feature][1]) / (scores[feature][0] - scores[feature][1]))\n",
    "\n",
    "print(scores)\n",
    "\n",
    "overallscoredf = pd.DataFrame(columns = ['feature', 'positiveCount', 'negativeCount', 'score'])\n",
    "\n",
    "for feature in scores.keys():\n",
    "    new_row = pd.Series({'feature': feature, 'positiveCount': scores[feature][0], 'negativeCount': scores[feature][1], 'score': scores[feature][2]})\n",
    "    overallscoredf = pd.concat([overallscoredf, new_row.to_frame().T], ignore_index=False)\n",
    "\n",
    "overallscoredf.to_csv('feature-scores_python_Spanish_English.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature sentiment per app\n",
    "\n",
    "scoredf = pd.DataFrame(columns = ['app', 'feature', 'positiveCount', 'negativeCount', 'score'])\n",
    "\n",
    "filelist = [file for file in os.listdir('review-files-combined-filtered_Spanish/')]\n",
    "\n",
    "with open('../googleplay-apps.txt') as appfile:\n",
    "    line = appfile.readline()\n",
    "\n",
    "    while(line):\n",
    "        app = line.strip()\n",
    "\n",
    "        if app == 'encode':\n",
    "            line = appfile.readline()\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv('review-files-combined-filtered_Spanish/' + app + '_Spanish_sentiment_standardized_filtered.csv')\n",
    "\n",
    "        appscores = defaultdict(list)\n",
    "        for feature in my_dict.keys():\n",
    "            feature = feature.lower()\n",
    "            appscores[feature] = [0, 0]\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            mentioned_features = [feature.strip() for feature in row['mentionedFeature'].split(',')]\n",
    "            #print(mentioned_features)\n",
    "            for feature in mentioned_features:\n",
    "                #print(feature)\n",
    "                if row['sentiment'] == 'POS':\n",
    "                    appscores[feature][0] += 1\n",
    "                elif row['sentiment'] == 'NEG':\n",
    "                    appscores[feature][1] -= 1\n",
    "\n",
    "        for feature in appscores.keys():\n",
    "            if appscores[feature][0] - appscores[feature][1] == 0:\n",
    "                appscores[feature].append(0)\n",
    "                continue\n",
    "            appscores[feature].append((appscores[feature][0] + appscores[feature][1]) / (appscores[feature][0] - appscores[feature][1]))\n",
    "\n",
    "        for feature in appscores.keys():\n",
    "            new_row = pd.Series({'app': app, 'feature': feature, 'positiveCount': appscores[feature][0], 'negativeCount': appscores[feature][1], 'score': appscores[feature][2]})\n",
    "            \n",
    "            scoredf = pd.concat([scoredf, new_row.to_frame().T], ignore_index=False)\n",
    "\n",
    "        line = appfile.readline()\n",
    "\n",
    "scoredf.to_csv('feature-scores-by-app-Spanish.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codeacademy\n",
      "datacamp\n",
      "learn-python-programiz\n",
      "mimo\n",
      "programming-hero\n",
      "programming-hub\n",
      "sololearn\n"
     ]
    }
   ],
   "source": [
    "# Overall sentiment per app\n",
    "sentimentdf = pd.DataFrame(columns = ['app', 'positiveCount', 'negativeCount', 'score'])\n",
    "\n",
    "with open('../googleplay-apps.txt') as appfile:\n",
    "    line = appfile.readline()\n",
    "\n",
    "    while(line):\n",
    "        app = line.strip()\n",
    "\n",
    "        if app == 'encode':\n",
    "            line = appfile.readline()\n",
    "            continue\n",
    "        \n",
    "        print(app)\n",
    "\n",
    "        df = pd.read_csv('review-files-combined_Spanish/' + app + '_Spanish_sentiment.csv')\n",
    "\n",
    "        positiveCount = 0\n",
    "        negativeCount = 0\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "\n",
    "            if row['sentiment'] == 'POS':\n",
    "                positiveCount += 1\n",
    "            elif row['sentiment'] == 'NEG':\n",
    "                negativeCount -= 1\n",
    "        \n",
    "        if positiveCount == 0 and negativeCount == 0:\n",
    "            score = 0\n",
    "        else:\n",
    "            score = (positiveCount + negativeCount) / (positiveCount - negativeCount)\n",
    "            \n",
    "        new_row = pd.Series({'app': app, 'positiveCount': positiveCount, 'negativeCount': negativeCount, 'score': score})\n",
    "        sentimentdf = pd.concat([sentimentdf, new_row.to_frame().T], ignore_index=False)\n",
    "\n",
    "        line = appfile.readline()\n",
    "\n",
    "sentimentdf.to_csv('app-scores_Spanish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming score for clarity and adding proportions of positive and negative reviews\n",
    "\n",
    "files = ['app-sentiment_Spanish.csv',\n",
    "         'feature-sentiment_Spanish.csv', \n",
    "         'feature-sentiment_Spanish_English.csv',\n",
    "         'feature-sentiment_python_Spanish.csv', \n",
    "         'feature-sentiment_python_Spanish_English.csv', \n",
    "         'feature-sentiment-by-app_Spanish.csv', \n",
    "         'feature-sentiment-by-app_Spanish_English.csv']\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    df = df.rename(columns={'score': 'aggregatedAverage'})\n",
    "\n",
    "    df['negativeCount'] = df['negativeCount']*(-1)\n",
    "\n",
    "    df['positiveProportion'] = df['positiveCount'] / (df['positiveCount'] + df['negativeCount'])\n",
    "    df['negativeProportion'] = 1 - df['positiveProportion']\n",
    "\n",
    "    df.to_csv(file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
